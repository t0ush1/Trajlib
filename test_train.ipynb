{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "    \"data_name\": \"chengdu\",\n",
    "    \"data_path\": \"/data/hetianran/didi/chengdu/gps_20161101\",\n",
    "    \"data_size\": 100000,\n",
    "    \"data_form\": \"roadnet\",\n",
    "    \"vocab_size\": 5000,  # set by data factory\n",
    "}\n",
    "\n",
    "prediction_task_config = {\n",
    "    \"task_name\": \"prediction\",\n",
    "    \"train_mode\": \"pre-train\",  # pre-train, fine-tune, test-only\n",
    "    \"dataset_prop\": (0.8, 0.1, 0.1),\n",
    "    \"input_len\": 10,\n",
    "    \"output_len\": 1,  # only 1\n",
    "}\n",
    "\n",
    "similarity_task_config = {\n",
    "    \"task_name\": \"similarity\",\n",
    "    \"train_mode\": \"test-only\",\n",
    "    \"dataset_prop\": (0, 0, 1),\n",
    "    \"variant\": \"cropped\",  # cropped, distorted\n",
    "    \"sub-task\": \"kNN\",  # kNN, CDD\n",
    "}\n",
    "\n",
    "filling_task_config = {\n",
    "    \"task_name\": \"filling\",\n",
    "    \"train_mode\": \"pre-train\",\n",
    "    \"dataset_prop\": (0.9, 0.1, 0),\n",
    "    \"sub-task\": \"autoregressive\",  # mlm, autoregressive\n",
    "}\n",
    "\n",
    "embedding_config = {\n",
    "    \"emb_name\": \"normal\",\n",
    "    \"emb_dim\": 256,\n",
    "    \"pre-trained\": False,\n",
    "    \"embs_path\": \"\",\n",
    "}\n",
    "\n",
    "encoder_config = {\n",
    "    \"encoder_name\": \"transformer\",\n",
    "    \"num_layers\": 6,\n",
    "    \"d_model\": embedding_config[\"emb_dim\"],\n",
    "    \"num_heads\": 8,\n",
    "    \"d_ff\": 2048,\n",
    "    \"dropout\": 0.1,\n",
    "}\n",
    "\n",
    "trainer_config = {\n",
    "    \"model_path\": \"./resource/model/backbone/backbone.pth\",\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"num_epochs\": 10,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss_function\": \"cross_entropy\",\n",
    "    \"lr_scheduler\": \"step_lr\",\n",
    "}\n",
    "\n",
    "config = {\n",
    "    \"data_config\": data_config,\n",
    "    \"task_config\": prediction_task_config,\n",
    "    \"embedding_config\": embedding_config,\n",
    "    \"encoder_config\": encoder_config,\n",
    "    \"trainer_config\": trainer_config,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trajlib.model.model_factory import create_model\n",
    "from trajlib.data.data_factory import create_data\n",
    "\n",
    "data, _ = create_data(config)\n",
    "tot = 0\n",
    "for traj in data.original:\n",
    "    tot += len(traj)\n",
    "print(tot / len(data.original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trajlib.model.embedding.embedding_trainer import EmbeddingTrainer\n",
    "from trajlib.model.embedding.gnn import GAETrainer\n",
    "from trajlib.model.embedding.node2vec import Node2VecTrainer\n",
    "from trajlib.data.data_factory import create_data\n",
    "\n",
    "mapper: dict[str, type[EmbeddingTrainer]] = {\n",
    "    \"node2vec\": Node2VecTrainer,\n",
    "    \"gat\": GAETrainer,\n",
    "    \"gcn\": GAETrainer,\n",
    "}\n",
    "\n",
    "if embedding_config[\"pre-trained\"]:\n",
    "    _, graph_data = create_data(config)\n",
    "    trainer = mapper[embedding_config[\"emb_name\"]](embedding_config, graph_data)\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 4 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/hetianran/.conda/envs/traj/lib/python3.10/site-packages/leuvenmapmatching/visualization.py:130: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(figwidth, height))\n",
      "/home/hetianran/.conda/envs/traj/lib/python3.10/site-packages/leuvenmapmatching/visualization.py:130: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(figwidth, height))\n",
      "/home/hetianran/.conda/envs/traj/lib/python3.10/site-packages/leuvenmapmatching/visualization.py:130: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(figwidth, height))\n",
      "/home/hetianran/.conda/envs/traj/lib/python3.10/site-packages/leuvenmapmatching/visualization.py:130: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(figwidth, height))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:no osmids!\n",
      "error:no osmids!\n",
      "error:no osmids!\n",
      "error:no osmids!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0530 14:43:41.464000 103172 site-packages/torch/multiprocessing/spawn.py:160] Terminating process 103485 via signal SIGTERM\n",
      "W0530 14:43:41.469000 103172 site-packages/torch/multiprocessing/spawn.py:160] Terminating process 103486 via signal SIGTERM\n",
      "W0530 14:43:41.471000 103172 site-packages/torch/multiprocessing/spawn.py:160] Terminating process 103487 via signal SIGTERM\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] failed (exitcode: 1) local_rank: 0 (pid: 103484) of fn: accelerate_run (start_method: fork)\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] Traceback (most recent call last):\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/hetianran/.conda/envs/traj/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 687, in _poll\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     self._pc.join(-1)\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/hetianran/.conda/envs/traj/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 203, in join\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     raise ProcessRaisedException(msg, error_index, failed_process.pid)\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] torch.multiprocessing.spawn.ProcessRaisedException: \n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] \n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] -- Process 0 terminated with the following error:\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] Traceback (most recent call last):\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/hetianran/.conda/envs/traj/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 90, in _wrap\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     fn(i, *args)\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/hetianran/.conda/envs/traj/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 611, in _wrap\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     ret = record(fn)(*args_)\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/hetianran/.conda/envs/traj/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     return f(*args, **kwargs)\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/tmp/ipykernel_103172/480669042.py\", line 7, in accelerate_run\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     runner = BaseRunner(config)\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/hetianran/trajectory/TrajMM/trajlib/runner/base_runner.py\", line 33, in __init__\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     self.model = create_model(config)\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/hetianran/trajectory/TrajMM/trajlib/model/model_factory.py\", line 104, in create_model\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     embedding = create_embedding(config)\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/hetianran/trajectory/TrajMM/trajlib/model/model_factory.py\", line 79, in create_embedding\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     raise ValueError()\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] ValueError\n",
      "E0530 14:43:41.926000 103172 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] \n"
     ]
    },
    {
     "ename": "ChildFailedError",
     "evalue": "\n============================================================\naccelerate_run FAILED\n------------------------------------------------------------\nFailures:\n  <NO_OTHER_FAILURES>\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2025-05-30_14:43:40\n  host      : gpu19.buaanlsde.org\n  rank      : 0 (local_rank: 0)\n  exitcode  : 1 (pid: 103484)\n  error_file: /tmp/torchelastic_fybjukk5/none_1rsjfktt/attempt_0/0/error.json\n  traceback : Traceback (most recent call last):\n    File \"/home/hetianran/.conda/envs/traj/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n      return f(*args, **kwargs)\n    File \"/tmp/ipykernel_103172/480669042.py\", line 7, in accelerate_run\n      runner = BaseRunner(config)\n    File \"/home/hetianran/trajectory/TrajMM/trajlib/runner/base_runner.py\", line 33, in __init__\n      self.model = create_model(config)\n    File \"/home/hetianran/trajectory/TrajMM/trajlib/model/model_factory.py\", line 104, in create_model\n      embedding = create_embedding(config)\n    File \"/home/hetianran/trajectory/TrajMM/trajlib/model/model_factory.py\", line 79, in create_embedding\n      raise ValueError()\n  ValueError\n  \n============================================================",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mChildFailedError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m      8\u001b[0m     runner\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# import os\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# accelerate_run(config)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mnotebook_launcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43maccelerate_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_port\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m29500\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/traj/lib/python3.10/site-packages/accelerate/launchers.py:245\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes, rdzv_backend, rdzv_endpoint, rdzv_conf, rdzv_id, max_restarts, monitor_interval, log_line_prefix_template)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;124m\"\u001b[39m, ELASTIC_LOG_LINE_PREFIX_TEMPLATE_PYTORCH_VERSION):\n\u001b[1;32m    244\u001b[0m         launch_config_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_line_prefix_template\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m log_line_prefix_template\n\u001b[0;32m--> 245\u001b[0m     \u001b[43melastic_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLaunchConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlaunch_config_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentrypoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProcessRaisedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/.conda/envs/traj/lib/python3.10/site-packages/torch/distributed/launcher/api.py:138\u001b[0m, in \u001b[0;36melastic_launch.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlaunch_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_entrypoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/traj/lib/python3.10/site-packages/torch/distributed/launcher/api.py:269\u001b[0m, in \u001b[0;36mlaunch_agent\u001b[0;34m(config, entrypoint, args)\u001b[0m\n\u001b[1;32m    262\u001b[0m     events\u001b[38;5;241m.\u001b[39mrecord(agent\u001b[38;5;241m.\u001b[39mget_event_succeeded())\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mis_failed():\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;66;03m# ChildFailedError is treated specially by @record\u001b[39;00m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;66;03m# if the error files for the failed children exist\u001b[39;00m\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;66;03m# @record will copy the first error (root cause)\u001b[39;00m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;66;03m# to the error file of the launcher process.\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChildFailedError(\n\u001b[1;32m    270\u001b[0m             name\u001b[38;5;241m=\u001b[39mentrypoint_name,\n\u001b[1;32m    271\u001b[0m             failures\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39mfailures,\n\u001b[1;32m    272\u001b[0m         )\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreturn_values\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ChildFailedError:\n",
      "\u001b[0;31mChildFailedError\u001b[0m: \n============================================================\naccelerate_run FAILED\n------------------------------------------------------------\nFailures:\n  <NO_OTHER_FAILURES>\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2025-05-30_14:43:40\n  host      : gpu19.buaanlsde.org\n  rank      : 0 (local_rank: 0)\n  exitcode  : 1 (pid: 103484)\n  error_file: /tmp/torchelastic_fybjukk5/none_1rsjfktt/attempt_0/0/error.json\n  traceback : Traceback (most recent call last):\n    File \"/home/hetianran/.conda/envs/traj/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n      return f(*args, **kwargs)\n    File \"/tmp/ipykernel_103172/480669042.py\", line 7, in accelerate_run\n      runner = BaseRunner(config)\n    File \"/home/hetianran/trajectory/TrajMM/trajlib/runner/base_runner.py\", line 33, in __init__\n      self.model = create_model(config)\n    File \"/home/hetianran/trajectory/TrajMM/trajlib/model/model_factory.py\", line 104, in create_model\n      embedding = create_embedding(config)\n    File \"/home/hetianran/trajectory/TrajMM/trajlib/model/model_factory.py\", line 79, in create_embedding\n      raise ValueError()\n  ValueError\n  \n============================================================"
     ]
    }
   ],
   "source": [
    "from accelerate import notebook_launcher\n",
    "\n",
    "from trajlib.runner.base_runner import BaseRunner\n",
    "\n",
    "\n",
    "def accelerate_run(config):\n",
    "    runner = BaseRunner(config)\n",
    "    runner.run()\n",
    "\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "accelerate_run(config)\n",
    "\n",
    "# notebook_launcher(accelerate_run, args=(config,), num_processes=4, use_port=\"29500\")\n",
    "\n",
    "# TODO debug embedding 预训练和 encoder 训练无法连续运行"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
